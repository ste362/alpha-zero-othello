# ğŸ§  AlphaZero for Othello â€“ Report & Code ğŸ²ğŸ“˜ğŸ’»

This repo contains both the **full implementation** of the AlphaZero algorithm ğŸ¤– **and** a detailed **PDF report**

---

## ğŸ§  About the Project

This project applies **AlphaZero** to the game of **Othello (Reversi)** âš«âšª  
It combines cutting-edge techniques in **reinforcement learning**  and **deep learning**  to create a self-learning game-playing agent 

### Topics Covered in the Report:
- ğŸš€ **AlphaZero Algorithm** â€“ Self-play, learning from scratch, and no human input needed ğŸ¯ğŸ§   
- ğŸ§© **Neural Network Architecture** â€“ CNNs and dense layers to predict moves and game outcomes ğŸ–¥ï¸ğŸ”®  
- ğŸŒ² **Monte Carlo Tree Search (MCTS)** â€“ How the agent searches and improves over time ğŸŒ³ğŸ•µï¸â€â™€ï¸  
- ğŸ”¬ **Training & Experiments** â€“ 6Ã—6 and 8Ã—8 board configurations, performance stats, and comparisons ğŸ“ˆğŸ§ª  
- ğŸ§  **Conclusions & Learnings** â€“ Key takeaways and ideas for improvements âœ¨ğŸ“˜

---

The code is a fork of https://github.com/suragnair/alpha-zero-general

## Improvements
The improvements in the code result in a 10x speedup in training time. As a result, the model can also be trained on lower-end hardware; I used a GTX 1050 Ti to obtain the reults showed in the report.
Additional improvements come from a different training strategy, which accelerated the policy learning process compared to traditional methods.
